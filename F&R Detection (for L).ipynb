{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065528bb-86b2-4fcb-b3fb-1a96db09a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.8641 - accuracy: 0.5000 - val_loss: 0.5685 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.6580 - accuracy: 0.5000 - val_loss: 0.6323 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4939 - accuracy: 0.7857 - val_loss: 0.4168 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4500 - accuracy: 0.8571 - val_loss: 0.9578 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.2414 - accuracy: 0.8571 - val_loss: 0.2038 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1466 - accuracy: 0.9286 - val_loss: 0.4951 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1455 - accuracy: 0.9286 - val_loss: 0.1684 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.3460 - accuracy: 0.9286 - val_loss: 1.9941 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.6068 - accuracy: 0.7857 - val_loss: 0.5682 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4281 - accuracy: 0.8571 - val_loss: 2.7509 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4805 - accuracy: 0.7857 - val_loss: 1.1177 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 4.0538 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 6s 4s/step - loss: 0.2056 - accuracy: 0.8571 - val_loss: 0.7147 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.0649 - accuracy: 0.9286 - val_loss: 0.1281 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.2307 - accuracy: 0.9286 - val_loss: 0.1534 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 12s 4s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4917 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.4095 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 8s 5s/step - loss: 2.8825e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 3.9973e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 8s 5s/step - loss: 4.0702e-05 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 8s 5s/step - loss: 1.2160e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.9681 - accuracy: 0.5000\n",
      "Validation Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Model Selection with Transfer Learning\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Adding custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the initial layers of the base model\n",
    "for layer in base_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Unfreeze more layers of the base model and fine-tune\n",
    "for layer in base_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue Training (Fine-tuning)\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Model Evaluation\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888acfcd-38d8-4d55-bc7d-f45208987ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 371ms/step\n",
      "C:\\Users\\Lenovo\\OneDrive\\Documents\\WhatsApp Image 2024-07-03 at 07.28.32_656eb071.jpg is AI-generated\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(model, img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    return 'Original' if prediction < 0.5 else 'AI-generated'\n",
    "\n",
    "# Example usage\n",
    "image_paths = [\n",
    "    \"C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Documents\\\\WhatsApp Image 2024-07-03 at 07.28.32_656eb071.jpg\",\n",
    "    # Add paths to your images\n",
    "]\n",
    "\n",
    "for img_path in image_paths:\n",
    "    result = predict_image(model, img_path)\n",
    "    print(f'{img_path} is {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366a430-e85a-4415-881e-0170236cc593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
